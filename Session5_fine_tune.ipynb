{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsenahmadi2003/cnn_ai/blob/main/Session5_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRKJckiTO5g0"
      },
      "source": [
        "# **`Import`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9Izdxt6O8QR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torchvision import datasets, models, transforms\n",
        "from __future__ import print_function\n",
        "import torchsummary\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3SwdYTPetQq"
      },
      "source": [
        "# **`Initialization`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUiHnbpZey5N"
      },
      "outputs": [],
      "source": [
        "batch_size =256\n",
        "num_class =10\n",
        "num_epochs = 25\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjHLez7Fe9ob"
      },
      "source": [
        "# **`Dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOJsYKL_fAdj"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\"./cifar_train\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\"./cifar_test\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQuN17hXjOHQ"
      },
      "source": [
        "# **`Data Loader`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb0siXfUjThd"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8Nm8MoVqDBC"
      },
      "outputs": [],
      "source": [
        "one_train_batch_imgs, one_train_batch_lbls = next(iter(train_loader))\n",
        "print(one_train_batch_imgs.shape)\n",
        "print(one_train_batch_lbls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eArx9RK0mxq"
      },
      "outputs": [],
      "source": [
        "for index, (images, labels) in enumerate(train_loader):\n",
        "    print(index, images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FftnHnZPvEI-"
      },
      "outputs": [],
      "source": [
        "dataloaders ={'train':train_loader,'test':test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJRpfDu0-8b"
      },
      "source": [
        "# **`Model`**\n",
        "\n",
        "---\n",
        "in_features:\n",
        "\n",
        "تعداد ورودی های لایه فولی کانکتد\n",
        "\n",
        "out_features:\n",
        "\n",
        "تعداد خروجی های لایه فولی کانکتد\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = models.resnet18(pretrained=True).to(device)\n",
        "\n",
        "layers = list(base.children())\n",
        "\n",
        "l1 = nn.Sequential(*layers[:-5])\n",
        "# print(l1)\n",
        "\n",
        "l2 = nn.Sequential(*layers[5])\n",
        "# print(l2)\n",
        "\n",
        "l3 = nn.Sequential(*layers[6])\n",
        "# print(l3)\n",
        "\n",
        "l4 = nn.Sequential(*layers[7:9])\n",
        "# print(l4)\n",
        "\n",
        "l5 = nn.Sequential(layers[9])\n",
        "# print(l5)"
      ],
      "metadata": {
        "id": "8Y7XMpdo8OmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vis(imgs, idx):\n",
        "    img = imgs[idx,...].abs().sum(1).squeeze(0)\n",
        "    img = np.moveaxis(img.cpu().detach().numpy(), 0, -1)\n",
        "    plt.imshow(img, interpolation='bilinear')\n",
        "    # plt.Show()"
      ],
      "metadata": {
        "id": "EzV2Xr-g8rVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, lbls = next(iter(dataloaders['train']))\n",
        "imgs = imgs.to(device)\n",
        "lbls = lbls.to(device)\n",
        "\n",
        "idx = torch.randint(0, batch_size, size=(1,))\n",
        "\n",
        "y1 = l1(imgs)\n",
        "print(y1.shape)\n",
        "# vis(y1, idx)\n",
        "\n",
        "y2 = l2(y1)\n",
        "print(y2.shape)\n",
        "\n",
        "y3 = l3(y2)\n",
        "print(y3.shape)\n",
        "\n",
        "y4 = l4(y3)\n",
        "print(y4.shape)\n",
        "\n",
        "n1 = nn.Conv2d(in_channels=64, out_channels=512, kernel_size=1, stride=8).to(device)\n",
        "z1 = n1(y1) * y4\n",
        "z1 = z1.view(z1.size(0), -1)\n",
        "print('z1: ', z1.shape)\n",
        "\n",
        "n2 = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=1, stride=4).to(device)\n",
        "z2 = n2(y2) * y4\n",
        "z2 = z2.view(z2.size(0), -1)\n",
        "print('z2: ', z2.shape)\n",
        "\n",
        "n3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=2).to(device)\n",
        "z3 = n3(y3) * y4\n",
        "z3 = z3.view(z3.size(0), -1)\n",
        "print('z3: ', z3.shape)\n",
        "\n",
        "zt = torch.cat((z1, z2, z3), dim=1)\n",
        "print(zt.shape)\n",
        "\n",
        "fc = nn.Linear(in_features=512*3, out_features=10, bias=False).to(device)\n",
        "output = fc(zt)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "80CgLxm98u2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD03LeL13WhO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class convnet(nn.Module):\n",
        "    def __init__(self, num_class):\n",
        "        super(convnet, self).__init__()\n",
        "        self.base = models.resnet18(pretrained=True)\n",
        "        self.base.fc = nn.Linear(in_features=512, out_features=10, bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.base(x)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lINbrIsVBZmj"
      },
      "outputs": [],
      "source": [
        "model = convnet(num_class).to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flag = False\n",
        "for name, param in model.named_parameters():\n",
        "    if not 'layer3.0' in name or flag:\n",
        "        param.requires_grad = True\n",
        "        print(name)\n",
        "        flag = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "    "
      ],
      "metadata": {
        "id": "pgax61K9ug2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, lbls = next(iter(dataloaders['train']))\n",
        "imgs = imgs.to(device)\n",
        "lbls = lbls.to(device)\n",
        "print(imgs.shape)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = torch.randint(0, batch_size, size=(1,))\n",
        "img = imgs[idx,...].squeeze(0)\n",
        "\n",
        "img = np.moveaxis(img.cpu().numpy(), 0, -1)\n",
        "img.shape\n",
        "\n",
        "plt.imshow(img, interpolation='bilinear')"
      ],
      "metadata": {
        "id": "-l7SKd6O47UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Config**"
      ],
      "metadata": {
        "id": "qsNVi-UiudfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkBEuffguQg6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**"
      ],
      "metadata": {
        "id": "jkZrd5U0xixu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZjjxaIkuRLt"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'test':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJFdmmRZvOQ_"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMpOKcJRuUgN"
      },
      "outputs": [],
      "source": [
        "model, hist = train_model(model, dataloaders, criterion, optimizer, num_epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4kEwAVFxwVJvP2wuZPBKU",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}